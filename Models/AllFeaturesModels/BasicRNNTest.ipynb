{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import SimpleRNN, Dense\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import RandomOverSampler\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['userId', 'DarknessEarlyMorningMean', 'DarknessMorningMean',\n",
      "       'DarknessAfternoonMean', 'DarknessEveningMean',\n",
      "       'DarknessEarlyMorningSum', 'DarknessMorningSum', 'DarknessAfternoonSum',\n",
      "       'DarknessEveningSum', 'DarknessShortestEarlyMorning',\n",
      "       ...\n",
      "       'ConversationEveningSum', 'ConversationShortestEarlyMorning',\n",
      "       'ConversationShortestMorning', 'ConversationShortestAfternoon',\n",
      "       'ConversationShortestEvening', 'ConversationLongestEarlyMorning',\n",
      "       'ConversationLongestMorning', 'ConversationLongestAfternoon',\n",
      "       'ConversationLongestEvening', 'PHQ9'],\n",
      "      dtype='object', length=106)\n"
     ]
    }
   ],
   "source": [
    "FeaturesPHQ9 = pd.DataFrame()\n",
    "FeaturesPHQ9 = pd.read_csv('../../dataset/BasicFeatures/Merged/AllBasicMerged.csv')\n",
    "print(FeaturesPHQ9.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "FeaturesPHQ9 = FeaturesPHQ9.drop(columns=['userId','WeekId'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     DarknessEarlyMorningMean  DarknessMorningMean  DarknessAfternoonMean  \\\n",
      "0                18372.333333         15542.000000            6005.769231   \n",
      "1                14846.090909         26047.000000            8724.642857   \n",
      "2                15283.095238         24830.333333            4187.125000   \n",
      "3                20652.578947             0.000000            8388.294118   \n",
      "4                11652.900000         19603.200000            4600.222222   \n",
      "..                        ...                  ...                    ...   \n",
      "247                  0.000000         27599.500000           13925.000000   \n",
      "248              34205.000000             0.000000           14905.333333   \n",
      "249              14656.416667         17738.625000            9287.833333   \n",
      "250              33182.000000             0.000000           13456.285714   \n",
      "251              10468.000000         21137.142857            5393.250000   \n",
      "\n",
      "     DarknessEveningMean  DarknessEarlyMorningSum  DarknessMorningSum  \\\n",
      "0            8243.647059                 220468.0             62168.0   \n",
      "1           13042.380952                 163307.0             78141.0   \n",
      "2            6444.769231                 320945.0             74491.0   \n",
      "3            8724.066667                 392399.0                 0.0   \n",
      "4            5645.600000                 233058.0            196032.0   \n",
      "..                   ...                      ...                 ...   \n",
      "247         11262.500000                      0.0             55199.0   \n",
      "248          8508.000000                  68410.0                 0.0   \n",
      "249          7238.833333                 175877.0            141909.0   \n",
      "250         12209.400000                  66364.0                 0.0   \n",
      "251          6958.000000                  73276.0            147960.0   \n",
      "\n",
      "     DarknessAfternoonSum  DarknessEveningSum  DarknessShortestEarlyMorning  \\\n",
      "0                 78075.0            140142.0                        4233.0   \n",
      "1                122145.0            273890.0                        3921.0   \n",
      "2                 33497.0             83782.0                        3832.0   \n",
      "3                142601.0            130861.0                        3894.0   \n",
      "4                 41402.0             84684.0                        3856.0   \n",
      "..                    ...                 ...                           ...   \n",
      "247               41775.0             22525.0                           0.0   \n",
      "248               44716.0             93588.0                       33593.0   \n",
      "249               55727.0             86866.0                        3632.0   \n",
      "250               94194.0             61047.0                       31274.0   \n",
      "251               43146.0             41748.0                        3887.0   \n",
      "\n",
      "     DarknessShortestMorning  ...  ConversationEveningSum  \\\n",
      "0                     7437.0  ...                132267.0   \n",
      "1                    22206.0  ...                195037.0   \n",
      "2                    22703.0  ...                144395.0   \n",
      "3                        0.0  ...                 93040.0   \n",
      "4                     3994.0  ...                122618.0   \n",
      "..                       ...  ...                     ...   \n",
      "247                  25149.0  ...                 31035.0   \n",
      "248                      0.0  ...                 75910.0   \n",
      "249                   5130.0  ...                108263.0   \n",
      "250                      0.0  ...                 88321.0   \n",
      "251                  12963.0  ...                114976.0   \n",
      "\n",
      "     ConversationShortestEarlyMorning  ConversationShortestMorning  \\\n",
      "0                                30.0                         50.0   \n",
      "1                                50.0                         71.0   \n",
      "2                                30.0                         60.0   \n",
      "3                                30.0                         71.0   \n",
      "4                                30.0                         40.0   \n",
      "..                                ...                          ...   \n",
      "247                              40.0                         50.0   \n",
      "248                              60.0                         71.0   \n",
      "249                              40.0                         50.0   \n",
      "250                              30.0                         61.0   \n",
      "251                              30.0                         40.0   \n",
      "\n",
      "     ConversationShortestAfternoon  ConversationShortestEvening  \\\n",
      "0                             30.0                         30.0   \n",
      "1                             30.0                         40.0   \n",
      "2                             50.0                         60.0   \n",
      "3                             50.0                         50.0   \n",
      "4                             40.0                         40.0   \n",
      "..                             ...                          ...   \n",
      "247                           50.0                         80.0   \n",
      "248                           40.0                         30.0   \n",
      "249                           40.0                         50.0   \n",
      "250                           50.0                         40.0   \n",
      "251                           30.0                         30.0   \n",
      "\n",
      "     ConversationLongestEarlyMorning  ConversationLongestMorning  \\\n",
      "0                             5821.0                      2289.0   \n",
      "1                             5980.0                      3096.0   \n",
      "2                             5635.0                       604.0   \n",
      "3                             6649.0                       544.0   \n",
      "4                             7737.0                       807.0   \n",
      "..                               ...                         ...   \n",
      "247                           2894.0                      2292.0   \n",
      "248                           9694.0                       131.0   \n",
      "249                           5950.0                      5807.0   \n",
      "250                           8829.0                       565.0   \n",
      "251                           3994.0                      1031.0   \n",
      "\n",
      "     ConversationLongestAfternoon  ConversationLongestEvening  PHQ9  \n",
      "0                          5706.0                      5579.0     0  \n",
      "1                         10174.0                      6990.0     0  \n",
      "2                          6646.0                      7009.0     1  \n",
      "3                         10880.0                      4406.0     0  \n",
      "4                          6666.0                      5177.0     0  \n",
      "..                            ...                         ...   ...  \n",
      "247                        5880.0                      2895.0     1  \n",
      "248                        1332.0                      6484.0     0  \n",
      "249                        2147.0                      6837.0     0  \n",
      "250                        3853.0                      6922.0     0  \n",
      "251                        4053.0                      4833.0     0  \n",
      "\n",
      "[252 rows x 104 columns]\n"
     ]
    }
   ],
   "source": [
    "dataClassification = FeaturesPHQ9.copy()\n",
    "columns = ['PHQ9']\n",
    "\n",
    "for column in columns:\n",
    "    dataClassification.loc[((dataClassification[column] > 0)& (dataClassification[column]<=5)), column] = 0\n",
    "    dataClassification.loc[((dataClassification[column] > 5)), column] = 1\n",
    "\n",
    "print(dataClassification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['DarknessEarlyMorningMean', 'DarknessMorningMean',\n",
      "       'DarknessAfternoonMean', 'DarknessEveningMean',\n",
      "       'DarknessEarlyMorningSum', 'DarknessMorningSum', 'DarknessAfternoonSum',\n",
      "       'DarknessEveningSum', 'DarknessShortestEarlyMorning',\n",
      "       'DarknessShortestMorning',\n",
      "       ...\n",
      "       'ConversationAfternoonSum', 'ConversationEveningSum',\n",
      "       'ConversationShortestEarlyMorning', 'ConversationShortestMorning',\n",
      "       'ConversationShortestAfternoon', 'ConversationShortestEvening',\n",
      "       'ConversationLongestEarlyMorning', 'ConversationLongestMorning',\n",
      "       'ConversationLongestAfternoon', 'ConversationLongestEvening'],\n",
      "      dtype='object', length=103)\n"
     ]
    }
   ],
   "source": [
    "X = dataClassification.drop(['PHQ9'], axis=1)\n",
    "# X = dataClassification.drop(['PHQ9'], axis=1)\n",
    "# y_PHQ9 = dataClassification['PHQ9']\n",
    "y_PHQ9Base = dataClassification['PHQ9']\n",
    "print(X.keys())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      0\n",
      "1      0\n",
      "2      1\n",
      "3      0\n",
      "4      0\n",
      "      ..\n",
      "247    1\n",
      "248    0\n",
      "249    0\n",
      "250    0\n",
      "251    0\n",
      "Name: PHQ9, Length: 252, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(y_PHQ9Base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the RandomOverSampler\n",
    "ros = RandomOverSampler(sampling_strategy='minority', random_state=42)\n",
    "\n",
    "# Fit and apply the random oversampling\n",
    "X_resampled, y_resampled = ros.fit_resample(X, y_PHQ9Base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y_PHQ9Base, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_trainOversampled, X_testOversampled, y_trainOversampled, y_testOversampled = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(201, 103)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN Model - original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "103\n",
      "201\n",
      "[[[ 4067.         16219.          5789.5        ...   948.\n",
      "    6868.          2753.        ]]\n",
      "\n",
      " [[ 9234.44444444 31530.25       13133.25       ...   319.\n",
      "    3428.          3206.        ]]\n",
      "\n",
      " [[27281.6        19708.         12088.14285714 ...  6011.\n",
      "    7949.          5971.        ]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[14140.75       19714.11111111  6819.88888889 ...  2012.\n",
      "    7846.          4904.        ]]\n",
      "\n",
      " [[10295.             0.             0.         ...  2366.\n",
      "     384.          1577.        ]]\n",
      "\n",
      " [[16708.09090909 14757.          9636.22222222 ...  2796.\n",
      "    7715.          6903.        ]]]\n",
      "(-1, 1, 103)\n",
      "(51, 1, 103)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "num_features = X_train.shape[1]\n",
    "print(num_features)\n",
    "\n",
    "# Adjust num_time_steps based on the size of your DataFrame\n",
    "num_time_steps = X_train.shape[0] // num_features  # Assuming each sample occupies num_features rows\n",
    "print(X_train.shape[0])\n",
    "\n",
    "# Reshape the DataFrame accordingly\n",
    "X_train_reshaped = X_train.values.reshape(-1, num_time_steps, num_features)\n",
    "\n",
    "# Assuming X_test is a DataFrame\n",
    "X_test_reshaped = X_test.values.reshape(X_test.shape[0], num_time_steps, num_features)\n",
    "print((-1, num_time_steps, num_features))\n",
    "print((X_test.shape[0], num_time_steps, num_features))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model parameters\n",
    "rnn_units = 128\n",
    "num_classes = len(np.unique(y_train))\n",
    "num_epochs = 50\n",
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(SimpleRNN(units=rnn_units, input_shape=(num_time_steps, num_features)))\n",
    "model.add(Dense(num_classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"/opt/homebrew/anaconda3/envs/tensorflowenv/lib/python3.9/site-packages/keras/engine/training.py\", line 1284, in train_function  *\n        return step_function(self, iterator)\n    File \"/opt/homebrew/anaconda3/envs/tensorflowenv/lib/python3.9/site-packages/keras/engine/training.py\", line 1268, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/opt/homebrew/anaconda3/envs/tensorflowenv/lib/python3.9/site-packages/keras/engine/training.py\", line 1249, in run_step  **\n        outputs = model.train_step(data)\n    File \"/opt/homebrew/anaconda3/envs/tensorflowenv/lib/python3.9/site-packages/keras/engine/training.py\", line 1050, in train_step\n        y_pred = self(x, training=True)\n    File \"/opt/homebrew/anaconda3/envs/tensorflowenv/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/opt/homebrew/anaconda3/envs/tensorflowenv/lib/python3.9/site-packages/keras/engine/input_spec.py\", line 298, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer \"sequential_13\" is incompatible with the layer: expected shape=(None, 1, 103), found shape=(None, 103)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[112], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/envs/tensorflowenv/lib/python3.9/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/var/folders/__/2j137gs56_s_11dyhp8v1q_w0000gn/T/__autograph_generated_filervucdh77.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     14\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(step_function), (ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m), ag__\u001b[38;5;241m.\u001b[39mld(iterator)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m     17\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/opt/homebrew/anaconda3/envs/tensorflowenv/lib/python3.9/site-packages/keras/engine/training.py\", line 1284, in train_function  *\n        return step_function(self, iterator)\n    File \"/opt/homebrew/anaconda3/envs/tensorflowenv/lib/python3.9/site-packages/keras/engine/training.py\", line 1268, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/opt/homebrew/anaconda3/envs/tensorflowenv/lib/python3.9/site-packages/keras/engine/training.py\", line 1249, in run_step  **\n        outputs = model.train_step(data)\n    File \"/opt/homebrew/anaconda3/envs/tensorflowenv/lib/python3.9/site-packages/keras/engine/training.py\", line 1050, in train_step\n        y_pred = self(x, training=True)\n    File \"/opt/homebrew/anaconda3/envs/tensorflowenv/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/opt/homebrew/anaconda3/envs/tensorflowenv/lib/python3.9/site-packages/keras/engine/input_spec.py\", line 298, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer \"sequential_13\" is incompatible with the layer: expected shape=(None, 1, 103), found shape=(None, 103)\n"
     ]
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=num_epochs, batch_size=batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 2ms/step - loss: 0.5881 - accuracy: 0.7059\n",
      "Test Accuracy: 0.7058823704719543\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(X_test_reshaped, y_test)\n",
    "print(\"Test Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN Model - Oversampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 7107 into shape (69,275,103)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[102], line 13\u001b[0m\n\u001b[1;32m     10\u001b[0m X_train_reshapedOversampled \u001b[38;5;241m=\u001b[39m X_trainOversampled\u001b[38;5;241m.\u001b[39mvalues\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, num_time_stepsOversampled, num_featuresOversampled)\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# Reshape the test DataFrame accordingly\u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m X_test_reshapedOversampled \u001b[38;5;241m=\u001b[39m \u001b[43mX_testOversampled\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_testOversampled\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_time_stepsOversampled\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_featuresOversampled\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# # Adjust num_time_steps based on the size of your DataFrame\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# num_time_stepsOversampled = X_trainOversampled.shape[0] // num_featuresOversampled  # Assuming each sample occupies num_features rows\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m# # Assuming X_test is a DataFrame\u001b[39;00m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m# X_test_reshapedOversampled = X_testOversampled.values.reshape(X_testOversampled.shape[0], num_time_stepsOversampled, num_featuresOversampled)\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: cannot reshape array of size 7107 into shape (69,275,103)"
     ]
    }
   ],
   "source": [
    "\n",
    "num_featuresOversampled = X_trainOversampled.shape[1]\n",
    "\n",
    "# Calculate the number of rows per sample after oversampling\n",
    "rows_per_sample_oversampled = X_trainOversampled.shape[0] // len(X_trainOversampled)\n",
    "\n",
    "# Adjust num_time_stepsOversampled based on the number of rows per sample\n",
    "num_time_stepsOversampled = X_trainOversampled.shape[0] // rows_per_sample_oversampled\n",
    "\n",
    "# Reshape the DataFrame accordingly\n",
    "X_train_reshapedOversampled = X_trainOversampled.values.reshape(-1, num_time_stepsOversampled, num_featuresOversampled)\n",
    "\n",
    "# Reshape the test DataFrame accordingly\n",
    "X_test_reshapedOversampled = X_testOversampled.values.reshape(X_testOversampled.shape[0], num_time_stepsOversampled, num_featuresOversampled)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # Adjust num_time_steps based on the size of your DataFrame\n",
    "# num_time_stepsOversampled = X_trainOversampled.shape[0] // num_featuresOversampled  # Assuming each sample occupies num_features rows\n",
    "\n",
    "# # Reshape the DataFrame accordingly\n",
    "# X_train_reshapedOversampled = X_trainOversampled.values.reshape(-1, num_time_stepsOversampled, num_featuresOversampled)\n",
    "# # Assuming X_test is a DataFrame\n",
    "# X_test_reshapedOversampled = X_testOversampled.values.reshape(X_testOversampled.shape[0], num_time_stepsOversampled, num_featuresOversampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model parameters\n",
    "rnn_units = 128\n",
    "num_classes = len(np.unique(y_trainOversampled))\n",
    "num_epochs = 50\n",
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(SimpleRNN(units=rnn_units, input_shape=(num_time_stepsOversampled, num_featuresOversampled)))\n",
    "model.add(Dense(num_classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Data cardinality is ambiguous:\n  x sizes: 1\n  y sizes: 275\nMake sure all arrays contain the same number of samples.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[100], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_reshapedOversampled\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_trainOversampled\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/envs/tensorflowenv/lib/python3.9/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/envs/tensorflowenv/lib/python3.9/site-packages/keras/engine/data_adapter.py:1852\u001b[0m, in \u001b[0;36m_check_data_cardinality\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m   1845\u001b[0m     msg \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m  \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m sizes: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   1846\u001b[0m         label,\n\u001b[1;32m   1847\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\n\u001b[1;32m   1848\u001b[0m             \u001b[38;5;28mstr\u001b[39m(i\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mnest\u001b[38;5;241m.\u001b[39mflatten(single_data)\n\u001b[1;32m   1849\u001b[0m         ),\n\u001b[1;32m   1850\u001b[0m     )\n\u001b[1;32m   1851\u001b[0m msg \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMake sure all arrays contain the same number of samples.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1852\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n",
      "\u001b[0;31mValueError\u001b[0m: Data cardinality is ambiguous:\n  x sizes: 1\n  y sizes: 275\nMake sure all arrays contain the same number of samples."
     ]
    }
   ],
   "source": [
    "model.fit(X_train_reshapedOversampled, y_trainOversampled, epochs=num_epochs, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"/opt/homebrew/anaconda3/envs/tensorflowenv/lib/python3.9/site-packages/keras/engine/training.py\", line 1852, in test_function  *\n        return step_function(self, iterator)\n    File \"/opt/homebrew/anaconda3/envs/tensorflowenv/lib/python3.9/site-packages/keras/engine/training.py\", line 1836, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/opt/homebrew/anaconda3/envs/tensorflowenv/lib/python3.9/site-packages/keras/engine/training.py\", line 1824, in run_step  **\n        outputs = model.test_step(data)\n    File \"/opt/homebrew/anaconda3/envs/tensorflowenv/lib/python3.9/site-packages/keras/engine/training.py\", line 1788, in test_step\n        y_pred = self(x, training=False)\n    File \"/opt/homebrew/anaconda3/envs/tensorflowenv/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/opt/homebrew/anaconda3/envs/tensorflowenv/lib/python3.9/site-packages/keras/engine/input_spec.py\", line 298, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer \"sequential_12\" is incompatible with the layer: expected shape=(None, 275, 103), found shape=(None, 1, 103)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[101], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m loss, accuracy \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test_reshapedOversampled\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_testOversampled\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTest Accuracy:\u001b[39m\u001b[38;5;124m\"\u001b[39m, accuracy)\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/envs/tensorflowenv/lib/python3.9/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/var/folders/__/2j137gs56_s_11dyhp8v1q_w0000gn/T/__autograph_generated_filebm2v27bh.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__test_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     14\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(step_function), (ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m), ag__\u001b[38;5;241m.\u001b[39mld(iterator)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m     17\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/opt/homebrew/anaconda3/envs/tensorflowenv/lib/python3.9/site-packages/keras/engine/training.py\", line 1852, in test_function  *\n        return step_function(self, iterator)\n    File \"/opt/homebrew/anaconda3/envs/tensorflowenv/lib/python3.9/site-packages/keras/engine/training.py\", line 1836, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/opt/homebrew/anaconda3/envs/tensorflowenv/lib/python3.9/site-packages/keras/engine/training.py\", line 1824, in run_step  **\n        outputs = model.test_step(data)\n    File \"/opt/homebrew/anaconda3/envs/tensorflowenv/lib/python3.9/site-packages/keras/engine/training.py\", line 1788, in test_step\n        y_pred = self(x, training=False)\n    File \"/opt/homebrew/anaconda3/envs/tensorflowenv/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/opt/homebrew/anaconda3/envs/tensorflowenv/lib/python3.9/site-packages/keras/engine/input_spec.py\", line 298, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer \"sequential_12\" is incompatible with the layer: expected shape=(None, 275, 103), found shape=(None, 1, 103)\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(X_test_reshapedOversampled, y_testOversampled)\n",
    "print(\"Test Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Diss",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
