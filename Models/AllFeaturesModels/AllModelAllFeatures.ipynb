{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report,confusion_matrix,roc_auc_score,roc_curve,auc,f1_score,precision_score\n",
    "from sklearn import metrics\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import cross_val_score, KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "PHQ9Post = pd.DataFrame()\n",
    "PHQ9Post = pd.read_csv('../../dataset/PHQ9/PHQ9PostClassified.csv')\n",
    "# print(PHQ9Pre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "AllMerged = pd.DataFrame()\n",
    "AllMerged = pd.read_csv('../../dataset/BasicFeatures/Merged/AllMerged.csv')\n",
    "# print(LockData)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to train and evaluate:\n",
    "def TrainandEval(model, features, target, name):\n",
    "    print(name)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "    print(\"Number of mislabeled points out of a total %d points : %d\" % (X_test.shape[0], (y_test != y_pred).sum()))\n",
    "    print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))\n",
    "    tn, fp, fn, tp = metrics.confusion_matrix(y_test, y_pred).ravel()\n",
    "    sensitivity = tp / (tp + fn)\n",
    "    specificity = tn / (tn + fp)\n",
    "    balanced_accuracy = (sensitivity + specificity) / 2\n",
    "\n",
    "    print(\"Sensitivity:\", sensitivity)\n",
    "    print(\"Specificity:\", specificity)\n",
    "    print(\"Balanced Accuracy:\", balanced_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#declare all model vars:\n",
    "LR = LogisticRegression()\n",
    "SVM = SVC()\n",
    "RF = RandomForestClassifier() \n",
    "XGB = XGBClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RunAllModels(data,PHQ9):\n",
    "    data = pd.merge(data, PHQ9, on='userId')\n",
    "    data = data.drop(columns=['userId','WeekId'])\n",
    "    X = data.drop(['PHQ9'], axis=1)\n",
    "    y= data['PHQ9']\n",
    "    TrainandEval(LogisticRegression(), X, y, 'LR')\n",
    "    TrainandEval(SVM, X, y, 'SVM')\n",
    "    TrainandEval(RF, X, y, 'RF')\n",
    "    TrainandEval(XGB, X, y, 'XGB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RunAllModelsNorm(data,PHQ9):\n",
    "    data = pd.merge(data, PHQ9, on='userId')\n",
    "    data = data.drop(columns=['userId','WeekId'])\n",
    "    X = data.drop(['PHQ9'], axis=1)\n",
    "\n",
    "    scaler = MinMaxScaler()\n",
    "    XNorm = scaler.fit_transform(X)\n",
    "\n",
    "    y= data['PHQ9']\n",
    "    TrainandEval(LogisticRegression(), XNorm, y, 'LR')\n",
    "    TrainandEval(SVM, XNorm, y, 'SVM')\n",
    "    TrainandEval(RF, XNorm, y, 'RF')\n",
    "    TrainandEval(XGB, XNorm, y, 'XGB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RunAllModelsOversampled(data,PHQ9):\n",
    "    data = pd.merge(data, PHQ9, on='userId')\n",
    "    data = data.drop(columns=['userId','WeekId'])\n",
    "    X = data.drop(['PHQ9'], axis=1)\n",
    "    y= data['PHQ9']\n",
    "\n",
    "    # Normatisation\n",
    "    scaler = MinMaxScaler()\n",
    "    XNorm = scaler.fit_transform(X)\n",
    "\n",
    "    # Oversampling\n",
    "    oversampler = SMOTE(random_state=42)\n",
    "    features_resampled, target_resampled = oversampler.fit_resample(XNorm, y)\n",
    "\n",
    "    TrainandEval(LogisticRegression(), features_resampled, target_resampled, 'LR')\n",
    "    TrainandEval(SVM, features_resampled, target_resampled, 'SVM')\n",
    "    TrainandEval(RF, features_resampled, target_resampled, 'RF')\n",
    "    TrainandEval(XGB, features_resampled, target_resampled, 'XGB')\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalised Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR\n",
      "Number of mislabeled points out of a total 43 points : 8\n",
      "Accuracy: 0.813953488372093\n",
      "Sensitivity: 0.5\n",
      "Specificity: 1.0\n",
      "Balanced Accuracy: 0.75\n",
      "SVM\n",
      "Number of mislabeled points out of a total 43 points : 5\n",
      "Accuracy: 0.8837209302325582\n",
      "Sensitivity: 0.6875\n",
      "Specificity: 1.0\n",
      "Balanced Accuracy: 0.84375\n",
      "RF\n",
      "Number of mislabeled points out of a total 43 points : 5\n",
      "Accuracy: 0.8837209302325582\n",
      "Sensitivity: 0.6875\n",
      "Specificity: 1.0\n",
      "Balanced Accuracy: 0.84375\n",
      "XGB\n",
      "Number of mislabeled points out of a total 43 points : 6\n",
      "Accuracy: 0.8604651162790697\n",
      "Sensitivity: 0.6875\n",
      "Specificity: 0.9629629629629629\n",
      "Balanced Accuracy: 0.8252314814814814\n"
     ]
    }
   ],
   "source": [
    "RunAllModelsNorm(AllMerged,PHQ9Post)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Oversampled Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR\n",
      "Number of mislabeled points out of a total 55 points : 7\n",
      "Accuracy: 0.8727272727272727\n",
      "Sensitivity: 0.7931034482758621\n",
      "Specificity: 0.9615384615384616\n",
      "Balanced Accuracy: 0.8773209549071619\n",
      "SVM\n",
      "Number of mislabeled points out of a total 55 points : 1\n",
      "Accuracy: 0.9818181818181818\n",
      "Sensitivity: 0.9655172413793104\n",
      "Specificity: 1.0\n",
      "Balanced Accuracy: 0.9827586206896552\n",
      "RF\n",
      "Number of mislabeled points out of a total 55 points : 3\n",
      "Accuracy: 0.9454545454545454\n",
      "Sensitivity: 0.896551724137931\n",
      "Specificity: 1.0\n",
      "Balanced Accuracy: 0.9482758620689655\n",
      "XGB\n",
      "Number of mislabeled points out of a total 55 points : 1\n",
      "Accuracy: 0.9818181818181818\n",
      "Sensitivity: 0.9655172413793104\n",
      "Specificity: 1.0\n",
      "Balanced Accuracy: 0.9827586206896552\n"
     ]
    }
   ],
   "source": [
    "RunAllModelsOversampled(AllMerged,PHQ9Post)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate sensitivity, specificity, and balanced accuracy\n",
    "def calculate_metrics(y_true, y_pred):\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "    sensitivity = tp / (tp + fn)\n",
    "    specificity = tn / (tn + fp)\n",
    "    balanced_accuracy = (sensitivity + specificity) / 2\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    precision = precision_score(y_true, y_pred)\n",
    "    return sensitivity, specificity, balanced_accuracy, accuracy, precision\n",
    "\n",
    "# Function to train and evaluate with k-fold cross-validation\n",
    "def TrainandEvalWithCrossValidation(model, features, target, name, cv=5):\n",
    "    print(name)\n",
    "    # Perform k-fold cross-validation\n",
    "    kfold = KFold(n_splits=cv, shuffle=True, random_state=42)\n",
    "    \n",
    "    accuracies = []\n",
    "    sensitivities = []\n",
    "    specificities = []\n",
    "    balanced_accuracies = []\n",
    "    precisions = []\n",
    "\n",
    "\n",
    "    for train_idx, test_idx in kfold.split(features):\n",
    "        X_train, X_test = features[train_idx], features[test_idx]\n",
    "        y_train, y_test = target[train_idx], target[test_idx]\n",
    "\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "\n",
    "        sensitivity, specificity, balanced_accuracy, accuracy, precision = calculate_metrics(y_test, y_pred)\n",
    "\n",
    "\n",
    "        sensitivities.append(sensitivity)\n",
    "        specificities.append(specificity)\n",
    "        balanced_accuracies.append(balanced_accuracy)\n",
    "        accuracies.append(accuracy)\n",
    "        precisions.append(precision)\n",
    "\n",
    "    # Print average metrics across all folds\n",
    "    print(\"Mean Accuracy:\", sum(accuracies) / len(accuracies))\n",
    "    print(\"Mean Balanced Accuracy:\", sum(balanced_accuracies) / len(balanced_accuracies))\n",
    "    print(\"Mean Sensitivity:\", sum(sensitivities) / len(sensitivities))\n",
    "    print(\"Mean Specificity:\", sum(specificities) / len(specificities))\n",
    "    print(\"Mean Precision:\", sum(precisions) / len(precisions))\n",
    "\n",
    "# Amend function to run all models with k-fold cross-validation\n",
    "def RunAllModelsNormWithCrossValidation(data, PHQ9, cv=5):\n",
    "    data = pd.merge(data, PHQ9, on='userId')\n",
    "    data = data.drop(columns=['userId', 'WeekId'])\n",
    "    X = data.drop(['PHQ9'], axis=1)\n",
    "    y = data['PHQ9']\n",
    "\n",
    "    scaler = MinMaxScaler()\n",
    "    XNorm = scaler.fit_transform(X)\n",
    "\n",
    "    \n",
    "    TrainandEvalWithCrossValidation(LogisticRegression(), XNorm, y, 'LR', cv)\n",
    "    TrainandEvalWithCrossValidation(SVM, XNorm, y, 'SVM', cv)\n",
    "    TrainandEvalWithCrossValidation(RF, XNorm, y, 'RF', cv)\n",
    "    TrainandEvalWithCrossValidation(XGB, XNorm, y, 'XGB', cv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR\n",
      "Mean Accuracy: 0.8874458874458874\n",
      "Mean Balanced Accuracy: 0.8735876623376623\n",
      "Mean Sensitivity: 0.8043181818181818\n",
      "Mean Specificity: 0.9428571428571428\n",
      "Mean Precision: 0.88015873015873\n",
      "SVM\n",
      "Mean Accuracy: 0.8777056277056277\n",
      "Mean Balanced Accuracy: 0.8566035353535353\n",
      "Mean Sensitivity: 0.7632070707070708\n",
      "Mean Specificity: 0.95\n",
      "Mean Precision: 0.8928571428571427\n",
      "RF\n",
      "Mean Accuracy: 0.8965367965367965\n",
      "Mean Balanced Accuracy: 0.8729608585858586\n",
      "Mean Sensitivity: 0.7605050505050506\n",
      "Mean Specificity: 0.9854166666666668\n",
      "Mean Precision: 0.9708333333333332\n",
      "XGB\n",
      "Mean Accuracy: 0.9062770562770565\n",
      "Mean Balanced Accuracy: 0.8910416666666666\n",
      "Mean Sensitivity: 0.8175000000000001\n",
      "Mean Specificity: 0.9645833333333333\n",
      "Mean Precision: 0.9311507936507937\n"
     ]
    }
   ],
   "source": [
    "RunAllModelsNormWithCrossValidation(AllMerged,PHQ9Post , 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-fold oversampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Amend function to run all models with k-fold cross-validation\n",
    "def RunAllModelsNormOversampledWithCrossValidation(data, PHQ9, cv=5):\n",
    "    data = pd.merge(data, PHQ9, on='userId')\n",
    "    data = data.drop(columns=['userId', 'WeekId'])\n",
    "    X = data.drop(['PHQ9'], axis=1)\n",
    "    y = data['PHQ9']\n",
    "\n",
    "    scaler = MinMaxScaler()\n",
    "    XNorm = scaler.fit_transform(X)\n",
    "\n",
    "\n",
    "\n",
    "     # Oversampling\n",
    "    oversampler = SMOTE(random_state=42)\n",
    "    features_resampled, target_resampled = oversampler.fit_resample(XNorm, y)\n",
    "\n",
    "\n",
    "    TrainandEvalWithCrossValidation(LogisticRegression(), features_resampled, target_resampled, 'LR', cv)\n",
    "    TrainandEvalWithCrossValidation(SVM, features_resampled, target_resampled, 'SVM', cv)\n",
    "    TrainandEvalWithCrossValidation(RF, features_resampled, target_resampled, 'RF', cv)\n",
    "    TrainandEvalWithCrossValidation(XGB, features_resampled, target_resampled, 'XGB', cv)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR\n",
      "Mean Accuracy: 0.9043650793650793\n",
      "Mean Balanced Accuracy: 0.9116012622997918\n",
      "Mean Sensitivity: 0.9555555555555555\n",
      "Mean Specificity: 0.867646969044028\n",
      "Mean Precision: 0.8760401853048914\n",
      "SVM\n",
      "Mean Accuracy: 0.9482804232804231\n",
      "Mean Balanced Accuracy: 0.9477004327371976\n",
      "Mean Sensitivity: 0.9933333333333334\n",
      "Mean Specificity: 0.9020675321410616\n",
      "Mean Precision: 0.9116712454212454\n",
      "RF\n",
      "Mean Accuracy: 0.9522486772486772\n",
      "Mean Balanced Accuracy: 0.9580195090856856\n",
      "Mean Sensitivity: 0.9555555555555555\n",
      "Mean Specificity: 0.9604834626158156\n",
      "Mean Precision: 0.9534981684981686\n",
      "XGB\n",
      "Mean Accuracy: 0.9482804232804234\n",
      "Mean Balanced Accuracy: 0.9530575755943402\n",
      "Mean Sensitivity: 0.9734188034188035\n",
      "Mean Specificity: 0.9326963477698772\n",
      "Mean Precision: 0.9288873626373626\n"
     ]
    }
   ],
   "source": [
    "RunAllModelsNormOversampledWithCrossValidation(AllMerged,PHQ9Post, 10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Diss",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
